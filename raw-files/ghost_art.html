<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
	<title>Gh0stinthemachine's Blog</title>
	
	<link rel="stylesheet" href="style.css">
	
</head>
	<body>

		<header>

			<h1 align="center"><strong>Computing Disruption</strong></h1>

		</header>

		<p> </p>
		<p>If you’re familiar with Moore’s Law (that the number of transistors in an computer chip double every year), it is in danger of dying out. The Law has since been revised to every 18 months, to every two years. Now we are in a very real danger of this exponential growth bottoming out. Transistors now are placed about as close to each other as is possible without quantum tunneling occurring and electrons passing from one transistor to another and shorting the whole thing out. The problem is that dominant computer chip architectures have not significantly evolved over time. They've been simply following a practice of squishing everything together smaller and smaller and tighter together and they've just about used up all of the squish-factor left.</p>
		<p> </p>

		<p>One of the emerging techs aiming to disrupt the computer world is to drop silicon in favor of graphene. Graphene is a lower-cost lower-energy-consuming material. In 2010, Andre Geim and Konstantin Novoselov were awarded Nobel Prizes in Physics for their discovery of graphene (brief summary of the history of this material can be read at <a href="https://interestingengineering.com/first-graphene-transistor-and-alfred-nobels-will-at-nobel-museum-can-impress-anyone" target="_blank">InterestingEngineering</a>). Of more immediate interest, January 11 of this year, <a href="https://www.nanowerk.com/nanotechnology-news2/newsid=51871.php" target="_blank">Nanowerks</a> reports researchers have announced a method of printing graphene ink electronics. (Original article from <a href="https://www.nature.com/articles/s41467-018-07632-w" target="_blank">Nature</a>.) While graphene is looking very impressive in its printing applications and how that can play in the future of IoT, actually using graphene in a CPU seems a long ways off. Graphene is actually compatible with silicon-based CMOS (<a href="https://www.extremetech.com/extreme/175727-ibm-builds-graphene-chip-thats-10000-times-faster-using-standard-cmos-processes" target="_blank">ExtremeTech</a>), but the problem lies in that graphene is a conductor and not a semi-conductor, i.e. there's always '1' but never '0', and that is an issue yet to be solved.</p>
		<p> </p>

		<p>Besides a materials change, the future of computing is also betting on scrapping the whole familiar computer chip architecture of smaller and faster and instead remapping computer chips to act like the neural pathways of the human brain, neural-patterned chips. This started with DARPA’s SyNAPSE project, which has since morphed into IBM’s <a href="http://research.ibm.com/articles/brain-chip.shtml" target="_blank">TrueNorth</a> chipset. TrueNorth slowly but steadily makes its inroads in the news. At the same time, University of Manchester has been working on its own neural architecture SpiNNaker which makes the news again January 3 of this year when ZDNet reports <a href="https://www.zdnet.com/article/this-million-core-supercomputer-inspired-by-the-human-brain-breaks-all-the-rules/?ftag=TRE-03-10aaa6b&bhid=27722432347738758889217627266628" target="_blank">SpiNNaker</a> has created their first low-power million-core supercomputer.</p>
		<p> </p>
		<p>Admittedly, these are cutting edge technologies just now appearing in computers far our of the reach of ordinary users, but this is just the beginning of an explosion in computing technology that, well, we ain’t seen nothin' yet. A simple tablet of today has the computing power many times that of the Apollo landings. As the technology matures, the computers of today will be retro toys on the shelf and the supercomputers of today will be tomorrow's smart home thermostat.</p>

    </body>
	
	<footer>
	 <p> </p>
	 <p> authored by: Liam Seeley</p>
	</footer>

</html>